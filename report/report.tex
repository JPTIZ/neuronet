%-------------------------------------------------------------------------------
\documentclass[twocolumn]{article}

%-------------------------------------------------------------------------------
% Packages
\usepackage[portuguese]{babel}
\usepackage[margin=2cm]{geometry}

\usepackage{environ}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{xcolor}

\graphicspath{{img/}}

%-------------------------------------------------------------------------------
% User-commands
\newcommand{\todo}[1]{{\color{red}{#1}}}

\NewEnviron{superframe}{%
    \begin{center}
        \fbox{\setlength{\fboxsep}{1em}\fbox{\parbox{5.5in}{%
            \BODY{}
        }}}
    \end{center}
}

\newmintedfile[textfile]{text}{autogobble, breaklines}

\newcommand{\hiddenlayers}{1, 2}
\newcommand{\hiddenneurons}{10, 100, 200}

%-------------------------------------------------------------------------------
% Project configs
\title{Relatório de I.A.: Redes Neurais (Trabalho 5)}
\author{Cauê Baasch de Souza \\
        João Paulo Taylor Ienczak Zanette}
\date{\today}

%-------------------------------------------------------------------------------
\begin{document}
    \maketitle{}

    \section{Resumo do projeto}

    \begin{description}
        \item [Linguagem:] Python 3.7
        \item [Bibliotecas:] Foram utilizadas:


            \begin{itemize}
                \item sklearn~\cite{sklearn} para modelagem das Redes Neurais;
                \item pillow~\cite{pillow} para conversão das entradas CSV em
                    imagens para este relatório;
                \item numpy~\cite{numpy} para representação matricial das
                    entradas.
            \end{itemize}
    \end{description}

    %===========================================================================
    \section{Configuração dos experimentos}

    Os experimentos foram realizados tomando como base dois conjuntos de dados
    já disponibilizados pelo professor na plataforma Moodle, sendo um para
    treinamento da rede neural e outro para testes. Ambos os conjuntos são
    formados por tuplas no formato $(output, pixel_1, pixel_2, \ldots,
    pixel_n)$, em que $output$ é um número simbolizando a categoria esperada
    para a análise do conjunto de pixeis denotados por $pixel_{i}$.

    O tratamento da rede neural foi separado em duas etapas: uma de
    treinamento, enviando à rede todas as tuplas do conjunto de treinamento em
    um grande lote, e outra para testes enviando as tuplas do conjunto de
    testes e, para cada uma, verificou-se se a previsão da rede foi feita
    corretamente ou não. Em ambas as etapas, todos os pixeis foram normalizados
    para o intervalo $[0, 1]$ por uma divisão simples
    (Equação~\ref{norm-pixel}).

    \begin{equation}
        \label{norm-pixel}
        NormPixel_i = \frac{Pixel_i}{255}
    \end{equation}

    A arquitetura da rede neural é formada por: uma camada de entrada com
    número de neurônios dependente do tamanho da entrada; um conjunto de
    camadas intermediárias com número de camadas variando entre
    $\{\hiddenlayers{}\}$, cada uma com número de neurônios variando entre
    $\{\hiddenneurons{}\}$; e uma camada de saída com 10 neurônios (um para
    cada classificação possível). A Tabela~\ref{configs} enumera as diferentes
    configurações de redes neurais para os experimentos.

    \begin{table}[ht]
        \begin{tabular}{c c c}
            \toprule
            Configuração & Nº de camadas & Nº de neurônios \\
            \midrule
            1  & 1 & (10) \\
            2  & 2 & (10, 10) \\
            3  & 2 & (10, 100) \\
            4  & 1 & (10) \\
            5  & 1 & (100) \\
            6  & 1 & (200) \\
            7  & 2 & (100, 10) \\
            8  & 2 & (100, 100) \\
            9  & 2 & (200, 100) \\
            10 & 2 & (200, 200) \\
            \bottomrule
        \end{tabular}
        \caption{%
            Enumeração das configurações de rede neural utilizadas nos
            experimentos.\label{configs}
        }
    \end{table}

    Quanto ao número de execuções, para fins de avaliação dos resultados foi
    feito um treinamento e teste para cada configuração descrita na
    Tabela~\ref{configs}, totalizando 10 execuções.

    %===========================================================================
    \section{Resultados obtidos}

    %---------------------------------------------------------------------------
    \subsection{Análise geral}

    A acurácia das diferentes configurações está expressa na
    Figura~\ref{accuracy}. No melhor dos casos, a rede obteve uma acurácia de
    cerca de 88\% para a configuração 9 (2 camadas de 200 e 100 neurônios
    respectivamente), e no pior caso 78.2\% para 1 camada de 10 neurônios.

    \begin{figure}[ht]
        \centering{}
        \def\svgwidth{\columnwidth}
        \input{img/accuracy.pdf_tex}
        \caption{%
            Acurácia da rede neural em diferentes configurações, dada pelo
            número de acertos dividido pelo número de entradas no conjunto de
            teste.\label{accuracy}
        }
    \end{figure}

    Na Figura~\ref{conf-matrix} está expressa a matriz de confusão para a
    configuração 9 quando avaliada para o conjunto de dados de teste. Para
    referência, a Tabela~\ref{label-nums} contém a enumeração das categorias.
    Considerando quando eram a categoria real, descatam-se Trouser e Shirt como
    categorias com respectivamente maior (98.4\%) e menor acurácia (73.3\%), e
    Shirt e Trouser como categorias de, respectivamente, maior (255) e menor
    (18) número de falsos positivos.

    Um fator interessante pode ser observado na exposição dos resultados: em
    246 dos 10000 casos de teste (totalizando 2.46\%), a rede não foi capaz de
    indicar categoria alguma, o que compõe 21.54\% das previsões erradas.

    \begin{table}[ht]
        \centering
        \begin{tabular}{c l}
            \toprule
            Nº & Categoria \\
            \midrule
            0 & T-shirt/top \\
            1 & Trouser \\
            2 & Pullover \\
            3 & Dress \\
            4 & Coat \\
            5 & Sandal \\
            6 & Shirt \\
            7 & Sneaker \\
            8 & Bag \\
            9 & Ankle boot \\
            \bottomrule
        \end{tabular}
        \caption{%
            Relação entre números das categorias e suas respectivas
            descrições.\label{label-nums}
        }
    \end{table}

    É importante apontar o motivo do número alto de falsos positivos de Shirt:
    dos 255 falsos positivos para essa categoria, 114 ocorreram quando a
    categoria real era T-Shirt. Assim, é possível perceber que a rede possui
    dificuldades de separar quando a imagem se trata de um ou de outro por
    conta de sua semelhança, que é notável no comparativo feito na
    Figura~\ref{shirt-compare}.

    \begin{figure}[h!]
        \centering{}
        \includegraphics[keepaspectratio,width=.4\columnwidth]{img/inputs/img-2570}
        \includegraphics[keepaspectratio,width=.4\columnwidth]{img/inputs/img-2611}
        \caption{%
            Comparativo entre uma das imagens da categoria T-Shirt dada pela
            rede neural como Shirt (esquerda) e uma das imagens da categoria
            Shirt dada como T-Shirt (direita). É possível perceber a semelhança
            das duas imagens quanto ao posicionamento e tamanho das mangas e
            seu formato.\label{shirt-compare}
        }
    \end{figure}

    Retomando a matriz de confusão, é possível notar que há uma correlação de
    que, dadas duas categorias distintas A e B, quando muitos objetos da
    categoria A são previstos como da categoria B, então provavelmente muitos
    objetos da categoria B também serão previstos como da categoria A. Essa
    correlação permite entender os falsos positivos da rede neural e concluir
    que há características muito semelhantes entre as categorias, fazendo com
    que a matriz de confusão se torne próxima de uma matriz simétrica.

    \begin{figure}[ht]
        \centering{}
        \def\svgwidth{\columnwidth}
        \input{img/confusion.pdf_tex}
        \caption{%
            Matriz de confusão para uma rede neural de 2 camadas de 100
            neurônios cada.\label{conf-matrix}
        }
    \end{figure}

    %---------------------------------------------------------------------------
    \subsection{Análise de Overfitting}

    Para perceber o efeito de \textit{Overfitting} (quando a rede neural acaba
    por descrever os dados de treinamento em vez de descrever o comportamento
    do problema), foi analisada a acurácia das configurações 1 e 9 para os
    dados de treinamento e teste, expressa na Figura~\ref{overfitting}.

    \begin{figure}[ht]
        \centering{}
        \def\svgwidth{\columnwidth}
        \input{img/overfitting.pdf_tex}
        \caption{%
            Acurácia das configurações 1 e 9 para os dados de treinamento e
            teste, demonstrando o efeito de Overfitting.\label{overfitting}
        }
    \end{figure}

    Observando o gráfico, é possível verificar que, apesar da acurácia para o
    conjunto de treinamento ter tido um aumento absoluto de 17\% em relação às
    configurações 1 e 9 (15.5\% de aumento relativo), o aumento absoluto para o
    conjunto de dados de teste foi de apenas 6\% (aumento relativo de 6.8\%).
    Analisando as configurações separadamente, a configuração 1 teve um
    decrécimo de acurácia de cerca de apenas 3\% ao se passar do conjunto de
    treinamento para o conjunto de teste, enquanto na configuração 9 esse
    decréscimo foi de cerca de 10\%.

    \bibliographystyle{unsrt}
    \bibliography{refs}
    \nocite{*}
\end{document}
