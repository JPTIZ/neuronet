%-------------------------------------------------------------------------------
\documentclass[twocolumn]{article}

%-------------------------------------------------------------------------------
% Packages
\usepackage[portuguese]{babel}
\usepackage[margin=2cm]{geometry}

\usepackage{environ}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{tikz}
\usepackage{xcolor}

%-------------------------------------------------------------------------------
% User-commands
\newcommand{\todo}[1]{{\color{red}{#1}}}

\NewEnviron{superframe}{%
    \begin{center}
        \fbox{\setlength{\fboxsep}{1em}\fbox{\parbox{5.5in}{%
            \BODY{}
        }}}
    \end{center}
}

\newmintedfile[textfile]{text}{autogobble, breaklines}

\newcommand{\hiddenlayers}{1, 2}
\newcommand{\hiddenneurons}{10, 50, 100}

%-------------------------------------------------------------------------------
% Project configs
\title{Relatório de I.A.: Redes Neurais (Trabalho 5)}
\author{Cauê Baasch de Souza \\
        João Paulo Taylor Ienczak Zanette}
\date{\today}

%-------------------------------------------------------------------------------
\begin{document}
    \maketitle{}

    \section{Resumo do projeto}

    \begin{description}
        \item [Linguagem:] Python 3.7
        \item [Biblioteca de Redes Neurais utilizada:] sklearn~\cite{sklearn}.
    \end{description}

    \section{Configuração dos experimentos}

    Os experimentos foram realizados tomando como base dois conjuntos de dados
    já disponibilizados pelo professor na plataforma Moodle, sendo um para
    treinamento da rede neural e outro para testes. Ambos os conjuntos são
    formados por tuplas no formato $(output, pixel_1, pixel_2, \ldots,
    pixel_n)$, em que $output$ é um número simbolizando a categoria esperada
    para a análise do conjunto de pixeis denotados por $pixel_{i}$.

    O tratamento da rede neural foi separado em duas etapas: uma de
    treinamento, enviando à rede todas as tuplas do conjunto de treinamento em
    um grande lote, e outra para testes enviando as tuplas do conjunto de
    testes e, para cada teste, validando se a previsão da rede foi feita
    corretamente ou não. Em ambas as etapas, todos os pixeis foram normalizados
    para o intervalo $[0, 1]$ por uma divisão simples
    (Equação~\ref{norm-pixel}).

    \begin{equation}
        \label{norm-pixel}
        NormPixel_i = \frac{Pixel_i}{255}
    \end{equation}

    A arquitetura da rede neural é formada por: uma camada de entrada com
    número de neurônios dependente do tamanho da entrada; um conjunto camadas
    intermediárias variando entre $\{\hiddenlayers{}\}$, cada uma com número de
    neurônios variando entre $\{\hiddenneurons{}\}$; e uma camada de saída com
    10 neurônios (um para cada classificação possível).

    Quanto ao número de execuções, foi feito um treinamento e teste para cada
    configuração possível dentre o número de camadas intermediárias e o número
    de neurônios, totalizando 12 testes.

    \subsection{Quantos e quais experimentos foram feitos até chegar no resultado final}

    Vários (mentira, foram só uns 2 depois que funcionou com a lib).

    \subsection{Como foi o treinamento}

    Foi bem divertido, obrigado.

    \section{Resultados obtidos}

    \subsection{Qual a taxa de acertos da rede}

    66\% eu acho, por aí.

    \subsection{Matriz de confusão}

    Que.

    \subsection{Exemplos de objetos que foram mal-classificados pela rede}

    *Sigh* isso vai dar um trabalho\ldots

    \subsection{Fatos que você achou interessante}

    Implementar backtracking é um belo cu mas foi legal.

    \bibliographystyle{unsrt}
    \bibliography{refs}
    \nocite{*}
\end{document}
